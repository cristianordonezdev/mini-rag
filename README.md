# 游 Mini RAG con ChromaDB, Hugging Face y Docker

Este proyecto es un ejemplo b치sico de un sistema **RAG (Retrieval-Augmented Generation)**.

Permite hacer preguntas sobre varios documentos  `.txt`, `.md`, `.log`, `.pdf` o `.docx` usando:

- 游빏 Embeddings generados con Hugging Face
- 游댍 B칰squeda sem치ntica con ChromaDB
- 游 Generaci칩n de respuestas con un LLM (v칤a Hugging Face Inference API)

---

## 游 Tecnolog칤as usadas

- Python
- ChromaDB (en Docker)
- Hugging Face Transformers
- LangChain
- Hugging Face Inference API

---

## 游늱 Instalaci칩n

```bash
git clone https://github.com/cristianordonezdev/mini-rag.git
cd mini-rag
python -m venv venv
source venv/bin/activate  # o .\venv\Scripts\activate en Windows
pip install -r requirements.txt
```

---

## 游냡 Levantar ChromaDB con Docker

```bash
docker compose up -d
```

---

## 游댏 Configurar Hugging Face Token

Crea un archivo `.env` en la ra칤z del proyecto con:

```
HF_API_TOKEN=tu_token_de_huggingface
```

---

## 游늯 Indexar documento

Coloca los documentos en `data/` y luego ejecuta:

```bash
python app/index.py
```

---

## 游눫 Hacer una pregunta

```bash
python app/ask.py
```

---

## 游닇 Autor

- Proyecto de pr치ctica RAG por cristianordonezdev

